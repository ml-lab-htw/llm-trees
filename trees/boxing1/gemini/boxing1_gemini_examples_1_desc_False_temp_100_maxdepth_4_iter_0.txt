```python
def predict(X: dict):
    nodes = 15 * [None]

    nodes[0] = X["Judge"] <= 4  # Split based on Judge (somewhat arbitrary but creates a tree)
    nodes[1] = X["Round"] <= 6  # Split rounds into first and second half
    nodes[2] = X["Official"] == 1 # Split based on official status
    nodes[3] = X["Judge"] <= 2
    nodes[4] = X["Round"] <= 3
    nodes[5] = X["Round"] <= 9
    nodes[6] = X["Judge"] <= 6
    nodes[7] = X["Round"] <= 10
    nodes[8] = X["Judge"] <= 8
    nodes[9] = X["Round"] <= 2
    nodes[10] = X["Round"] <= 4
    nodes[11] = X["Round"] <= 8
    nodes[12] = X["Judge"] <= 1
    nodes[13] = X["Round"] <= 5
    nodes[14] = X["Round"] <= 7


    if nodes[0]:
        if nodes[1]:
            if nodes[2]:
                if nodes[3]:
                    prediction = 1
                else:
                    prediction = 0
            else:
                if nodes[4]:
                    prediction = 1
                else:
                    prediction = 0

        else:
             if nodes[5]:
                if nodes[6]:
                    prediction = 0
                else:
                    prediction = 1
             else:
                if nodes[7]:
                    prediction = 0
                else:
                    prediction = 1


    else: # Judge > 4
        if nodes[8]:
            if nodes[11]:
                if nodes[9]:
                    prediction = 1
                else:
                    if nodes[10]:
                        prediction = 0
                    else:
                        prediction = 1

            else:
                if nodes[13]:
                    prediction = 1
                else:
                    prediction = 0


        else:  # Judge > 8
            if nodes[14]:
                 if nodes[12]:
                    prediction = 0
                 else:
                    prediction = 1
            else:
                prediction = 1

    return prediction, nodes

```


This code defines a decision tree function `predict(X)` that takes a dictionary of features as input and returns a prediction (0 or 1) and a list of truth values for the inner nodes.  It uses the provided feature names ("Judge", "Official", "Round") and creates a tree structure with branching logic based on various conditions.  Note that the choices of thresholds (e.g., `Judge <= 4`, `Round <= 6`) are somewhat arbitrary as no training data was provided, but the structure demonstrates how a decision tree with a depth of 4 (or up to the max of 15) could be implemented. The function also ensures the number of inner nodes are within the specified range (4-15). It prioritizes "Judge" and "Round" features in the early splits, assuming they might be more influential, but this is just for illustrative purposes without real data.  The actual performance of this tree on real-world boxing data is unknown and likely poor without training.