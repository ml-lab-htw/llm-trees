```python
def predict(X: dict):
    nodes = 3 * [None]
    nodes[0] = X["Judge"] <= 4  # Split based on Judge (somewhat arbitrary)
    nodes[1] = X["Round"] <= 6   # Split based on Round
    nodes[2] = X["Official"] == 1 # Split based on Official status

    if nodes[0]:
        if nodes[1]:
            if nodes[2]:
                prediction = 1 # Lewis
            else:
                prediction = 0 # Holyfield
        else:
            prediction = 1 # Lewis (Assume later rounds favor Lewis if Judge <=4)
    else:
        if nodes[1]:
            prediction = 0 # Holyfield (Assume earlier rounds favor Holyfield if Judge > 4)
        else:
            if nodes[2]:
                prediction = 1 # Lewis
            else:
                prediction = 0 # Holyfield
    return prediction, nodes
```

**Explanation and Justification:**

Since we don't have actual data to train on, we create a plausible decision tree structure using the provided features.  The goal is to demonstrate the requested format and a reasonable (though not data-driven) decision logic.

* **Maximum Depth 3:** The code ensures the tree has a depth of 3.
* **Inner Nodes (3-7):**  The code uses 3 inner nodes.
* **Feature Importance (Simulated):** Without training data, we can't determine true feature importance.  I've made some assumptions:
    * `Judge`:  I'm assuming different judges might have different biases, so this could be an important initial split.
    * `Round`:  The round number could be significant, as fighter performance and strategy can change throughout the match.
    * `Official`:  Whether a judge is "official" could also influence the decision.

* **Splitting Logic (Arbitrary):** The specific split points (e.g., `Judge <= 4`, `Round <= 6`) are arbitrary because we lack real data.  With data, we'd use algorithms to find optimal splits.

* **Predictions (Plausible):**  The predictions (Lewis or Holyfield winning a round) are assigned within the tree branches.  Again, these are plausible examples, not based on actual fight outcomes.


**Important Notes:**

* This decision tree is entirely synthetic.  Its performance on real boxing data would likely be poor.
* To build a useful decision tree, you need a labeled dataset and should use libraries like scikit-learn in Python.  The `DecisionTreeClassifier` in scikit-learn will automatically determine the best features, splits, and tree structure based on the data.