


```python
def predict(X: dict):
    nodes = 6 * [None]  # Initialize a list for truth values of inner nodes

    nodes[0] = X['Official'] == 1  # Official Judge?
    nodes[1] = X['Round'] <= 4      # Round <= 4?
    nodes[2] = X['Judge'] == 0      # Judge is E. Williams?
    nodes[3] = X['Round'] <= 8      # Round <= 8?
    nodes[4] = X['Judge'] == 0    # Judge is E.Williams # Example, adapt as needed
    nodes[5] = X['Round'] <= 7     # Example, adapt as needed


    if nodes[0]:  # Official Judge = Yes
        if nodes[1]:  # Round <= 4
            if nodes[2]:  # Judge is E. Williams
                prediction = 1  # Lewis
            else:
                prediction = 0  # Holyfield
        else:  # Round > 4
            if nodes[3]:  # Round <= 8
                prediction = 1  # Lewis
            else:
                prediction = 0  # Holyfield
    else:  # Official Judge = No
        if nodes[4]: #Judge is E. Williams
             if nodes[5]: # Round <=7
                prediction = 1
             else:
                prediction = 0
        else:
            prediction = 0 #Example -  Adapt based on expected behavior



    return prediction, nodes

```

**Explanation and Improvements:**

* **Node List:**  The `nodes` list now stores the truth values (True/False) of the conditions at each inner node.  This provides a record of the path taken through the tree for a given input.
* **Thresholds:** I've filled in some reasonable placeholder thresholds based on the pseudo-code example.  You'll want to adjust these based on domain knowledge or, ideally, by training the tree on data.
* **Unofficial Judges:** The `else` branch for "Official Judge = No" is now populated with further splits based on Judge and Round, similar to the official judge branch, but with different potential thresholds. This branch addresses the scenario where the judge is not official and makes predictions based on different criteria, albeit hypothetical in this example.
* **Depth and Complexity:** The tree's structure roughly follows the pseudo-code logic, but simplified to ensure it doesn't exceed the maximum depth of 5. The added conditions for non-official judges increase the complexity slightly while keeping the depth manageable.


**Important:**  This function is still a *hand-crafted* example. To get a truly effective decision tree, you *must* train it on real data. This code provides a template and illustrates the required format, but the specific splits and predictions will likely be different after training.  Use a machine learning library like scikit-learn to build and train your tree.