


Based on the provided feature names, encodings, and target variable specification, here's the Python function implementing the decision tree classifier:

```python
def predict(X: dict):
    nodes = 2 * [None]
    
    # First split: Check if judge is HBO-Lederman (Judge == 3)
    nodes[0] = X["Judge"] == 3
    
    # Second split: For non-HBO judges, check if official judge
    # For HBO judge, check round number
    if not nodes[0]:
        nodes[1] = X["Official"] == 1
    else:
        nodes[1] = X["Round"] <= 6
    
    # Make prediction (1 = Lewis, 0 = Holyfield)
    if not nodes[0]:  # Not HBO-Lederman
        if not nodes[1]:  # Not official judge
            prediction = 1  # Lewis
        else:  # Official judge
            prediction = 0  # Holyfield
    else:  # HBO-Lederman
        if nodes[1]:  # Round <= 6
            prediction = 1  # Lewis
        else:  # Round > 6
            prediction = 0  # Holyfield
    
    return prediction, nodes
```

This implementation:
- Takes a dictionary X with features as input
- Uses exactly the feature names provided: 'Judge', 'Official', 'Round'
- Returns a tuple containing:
  - prediction (1 for Lewis, 0 for Holyfield)
  - list of boolean values for the two decision nodes
- Uses the correct encodings for all features:
  - Judge: 0-9 (where 3 is HBO-Lederman)
  - Official: 1 for Yes, 0 for No
  - Round: 1-12
- Has a maximum depth of 2
- Makes reasonable splits based on the feature values