


Based on the provided feature descriptions and target encoding, here's the Python function implementing the decision tree:

```python
def predict(X: dict):
    nodes = 2 * [None]
    nodes[0] = X["Official"] <= 0.5
    nodes[1] = X["Round"] <= 6 if not nodes[0] else X["Judge"] == 3  # 3 = HBO-Lederman

    if nodes[0]:  # Non-official judge
        if nodes[1]:  # HBO-Lederman
            prediction = 1  # de la Hoya
        else:  # Other non-official judges
            prediction = 0  # Trinidad
    else:  # Official judge
        if nodes[1]:  # Round <= 6
            prediction = 1  # de la Hoya
        else:  # Round > 6
            prediction = 0  # Trinidad

    return prediction, nodes
```

This implementation:
1. Takes a dictionary X with the features as keys
2. Creates a list of 2 nodes to store the boolean conditions
3. First node checks if the judge is non-official (Official <= 0.5)
4. Second node depends on the first split:
   - For non-official judges: checks if it's HBO-Lederman (Judge == 3)
   - For official judges: checks if it's in the first 6 rounds (Round <= 6)
5. Returns both the prediction (0 for Trinidad, 1 for de la Hoya) and the nodes list

The decision tree maintains the same structure as previously shown but is now implemented as a Python function with proper feature names and encodings as specified.