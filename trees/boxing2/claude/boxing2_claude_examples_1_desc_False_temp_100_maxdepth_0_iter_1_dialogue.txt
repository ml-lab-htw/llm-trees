


Based on the provided feature descriptions and target encoding, I'll create a decision tree function that incorporates the most important decision points and returns both the prediction (0 for Trinidad, 1 for de la Hoya) and the node decisions:

```python
def predict(X: dict):
    nodes = 4 * [None]
    
    # First split on whether it's an official judge
    nodes[0] = X["Official"] <= 0
    
    # For unofficial judges, split on whether it's HBO-Lederman
    nodes[1] = X["Judge"] == 3
    
    # For official judges, split on whether it's Hamada
    nodes[2] = X["Judge"] == 0
    
    # Split on round number for Hamada's decisions
    nodes[3] = X["Round"] <= 8
    
    if nodes[0]:  # Unofficial judge
        if nodes[1]:  # HBO-Lederman
            prediction = 1  # de la Hoya
        else:
            prediction = 0  # Trinidad
    else:  # Official judge
        if nodes[2]:  # Hamada
            if nodes[3]:  # Round <= 8
                prediction = 1  # de la Hoya
            else:
                prediction = 0  # Trinidad
        else:
            prediction = 0  # Trinidad
            
    return prediction, nodes
```

This decision tree function:
1. First checks if the judge is official or not
2. For unofficial judges, checks if it's HBO-Lederman (who tended to favor de la Hoya)
3. For official judges, checks if it's Hamada
4. For Hamada's decisions, considers the round number (with a split at round 8)

The function returns:
- prediction: 0 for Trinidad, 1 for de la Hoya
- nodes: list of boolean values representing the conditions at each decision node