


Based on the provided information and examples, I'll create a Python function that implements the decision tree for predicting which boxer won each round. Here's the function:

```python
def predict(X: dict):
    nodes = 3 * [None]
    nodes[0] = X["Official"] <= 0.5
    nodes[1] = X["Round"] <= 6.5
    nodes[2] = X["Judge"] <= 2.5  # G. Hamada, B. Logist, J. Roth are 0, 1, 2

    if nodes[0]:
        if nodes[1]:
            prediction = 1  # de la Hoya
        else:
            prediction = 0  # Trinidad
    else:
        if nodes[2]:
            prediction = 0  # Trinidad
        else:
            prediction = 1  # de la Hoya

    return prediction, nodes
```

Explanation:

1. The function takes a dictionary `X` as input, containing the features.

2. We create a list `nodes` to store the truth values of the inner nodes.

3. The first split is based on whether the judge is official or not (`Official <= 0.5`).

4. For unofficial judges, we split based on the round (`Round <= 6.5`).

5. For official judges, we split based on the specific judge (`Judge <= 2.5`).

6. The prediction is made based on these splits:
   - Unofficial judges in earlier rounds (1-6) favor de la Hoya (1)
   - Unofficial judges in later rounds (7-12) favor Trinidad (0)
   - Official judges G. Hamada, B. Logist, and J. Roth (0, 1, 2) favor Trinidad (0)
   - Other official judges favor de la Hoya (1)

7. The function returns the prediction (0 for Trinidad, 1 for de la Hoya) and the list of node truth values.

This function follows the structure of the decision tree we created earlier and uses the exact keys and encodings provided in the feature descriptions.