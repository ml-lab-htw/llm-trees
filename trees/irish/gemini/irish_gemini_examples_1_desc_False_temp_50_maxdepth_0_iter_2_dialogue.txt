


```python
def predict(X: dict):
    """
    Predicts whether a student obtained a school leaving certificate.

    Args:
        X (dict): A dictionary of features.

    Returns:
        tuple: A tuple containing the prediction (0 or 1) and a list of truth values for inner nodes.
    """
    nodes = 4 * [None]  # Adjusted for the number of inner nodes in our tree

    nodes[0] = X["Educational_level"] <= 5
    nodes[1] = X["Type_school"] == 0  # primary_terminal_leaver
    nodes[2] = X["DVRT"] <= 45  # Using a more specific threshold
    nodes[3] = X["Prestige_score"] <= 12  # Another more specific threshold



    if nodes[0]:
        if nodes[1]:
            prediction = 0  # Primary terminal leaver => No certificate
        else:
            if nodes[2]:
                prediction = 0  # Low DVRT score => No certificate
            else:
                prediction = 1 # Higher DVRT score => Certificate
    else:  # Educational level > 5
        if X["Type_school"] == 2: # vocational
            if nodes[3]:
                prediction = 0 # Low prestige score, vocational school => No Certificate
            else:
                prediction = 1 # Higher prestige score, vocational school => Certificate

        else:  #  Secondary or continuing education => Certificate
            prediction = 1

    return prediction, nodes


# Example Usage (replace with your actual feature data)
example_features = {
    'Sex': 0,
    'DVRT': 60,
    'Educational_level': 7,
    'Prestige_score': 15,
    'Type_school': 0
}


prediction, node_values = predict(example_features)
print(f"Prediction: {prediction}")
print(f"Node values: {node_values}")




example_features2 = {
    'Sex': 0,
    'DVRT': 30,
    'Educational_level': 3,
    'Prestige_score': 15,
    'Type_school': 1
}


prediction2, node_values2 = predict(example_features2)
print(f"Prediction: {prediction2}")
print(f"Node values: {node_values2}")



example_features3 = {
    'Sex': 1,
    'DVRT': 70,
    'Educational_level': 10,
    'Prestige_score': 20,
    'Type_school': 1  # secondary_terminal_leaver
}

prediction3, node_values3 = predict(example_features3)
print(f"Prediction: {prediction3}")
print(f"Node values: {node_values3}")




```



**Key Changes and Improvements:**

* **Specific Thresholds:** Replaced placeholder thresholds with more concrete values (45 for DVRT, 12 for Prestige). These are still estimates, and in a real application, these would be learned from data.
* **Encoding Alignment:** Used the provided encoding for `Type_school` (0, 1, 2) in the conditions.
* **Simplified Structure:** Streamlined the `if/else` structure to more closely match the proposed decision tree logic, making it clearer and more efficient.
* **Node List:**  The `nodes` list now correctly reflects the truth values of each decision node.
* **Docstring:** Added a docstring to explain the function's purpose, arguments, and return values.


This revised function provides a more accurate and usable implementation of the decision tree logic, properly handling the feature encodings and returning the prediction and node values as required.  Remember, the accuracy of this tree depends heavily on the validity of the assumptions made about the relationships between the features and the target variable.  Real-world data is crucial for building a truly effective model.