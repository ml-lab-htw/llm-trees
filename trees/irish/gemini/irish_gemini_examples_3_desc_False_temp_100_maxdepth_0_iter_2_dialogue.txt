


```python
def predict(X: dict):
    nodes = 4 * [None]

    nodes[0] = X["Educational_level"] <= 5  # Split on educational level
    nodes[1] = X["Type_school"] == 0  # primary_terminal_leaver
    nodes[2] = X["DVRT"] <= 40
    nodes[3] = X["Prestige_score"] <= 10


    if nodes[0]:  # Educational level <= 5
        if nodes[1]:  # Primary terminal leaver
            prediction = 0  # No Certificate
        else:  # Not primary terminal leaver
            if nodes[2]:  # DVRT <= 40
                prediction = 0  # No Certificate
            else:  # DVRT > 40
                prediction = 1  # Certificate
    else:  # Educational level > 5
        if X["Type_school"] == 2:  # vocational
            if nodes[3]: # Prestige score <= 10
                prediction = 0 #No certificate
            else: # Prestige score > 10
                prediction = 1 #Certificate
        else:  #  secondary_terminal_leaver or something else
            prediction = 1  # Certificate


    return prediction, nodes
```


**Explanation and Improvements:**

1. **Clearer Feature Usage:** The code now directly uses the provided feature keys (e.g., "Educational_level", "Type_school", "DVRT", "Prestige_score") and their encoding.

2. **Thresholds:** Reasonable threshold values are incorporated based on the earlier discussion.  For example, `Educational_level <= 5` separates lower educational attainment from higher.  `DVRT <= 40` is a placeholder; a real-world analysis would determine a more appropriate threshold. The same applies to the `Prestige_score` threshold.

3. **Simplified Structure:** The code mirrors the decision tree logic closely, making it easier to follow.  The nested `if/else` statements correspond to the branches of the tree.

4. **Consistent Output:**  The function returns the prediction (0 or 1) and the `nodes` list containing the truth values (0 or 1) of the conditions at each inner node, as requested.


**Example Usage:**

```python
example_student = {
    'Sex': 1,
    'DVRT': 35,
    'Educational_level': 7,
    'Prestige_score': 8,
    'Type_school': 0
}

prediction, nodes = predict(example_student)
print(f"Prediction: {prediction}")
print(f"Nodes: {nodes}")
```


This example demonstrates how to use the `predict` function. You would replace `example_student` with the actual feature values for a student. The function will output the predicted outcome (0 or 1) and the truth values of the internal nodes.  This allows you to trace the path taken through the decision tree for a particular input.