


Here's the Python function based on the decision tree we discussed previously. The function uses the feature names and target mappings you provided, and it will return both a prediction and a list that represents the truth values of the inner node conditions:

```python
def predict(X: dict):
    nodes = 2 * [None]
    
    # First decision node: Educational level attained
    nodes[0] = X["Educational_level"] <= 5
    
    # Second decision node: Type of school, only evaluated if Educational level is <= 5
    if nodes[0]:
        nodes[1] = X["Type_school"] == 0  # Checking if Type of school is primary_terminal_leaver (0)
        
        if nodes[1]:
            prediction = 0  # No school leaving certificate
        else:
            prediction = 0  # No school leaving certificate
    else:
        prediction = 1  # School leaving certificate taken

    return prediction, nodes
```

### Explanation:
1. **nodes[0]**: This represents the first decision node based on the feature `Educational_level`. If the educational level is less than or equal to 5 (i.e., `Junior_cycle_terminal_leaver` or below), this node evaluates to `True`, otherwise `False`.
   
2. **nodes[1]**: This represents the second decision node, which is only evaluated if the first node (`Educational_level <= 5`) is `True`. It checks if the `Type_school` is `primary_terminal_leaver` (0). If the student attended a primary terminal leaver school, it is more likely that they did not obtain the school leaving certificate.

3. **Prediction**:
   - If both nodes are `True` (i.e., `Educational_level <= 5` and `Type_school == 0`), the prediction is `0` (no school leaving certificate).
   - If the first node is `True` but the second node is `False` (i.e., attending secondary or vocational school with an educational level of 5 or less), the prediction is still `0`.
   - If the first node is `False` (i.e., `Educational_level > 5`), the prediction is `1` (school leaving certificate taken).

This function should work as intended based on the given feature mappings and the structure of the decision tree.