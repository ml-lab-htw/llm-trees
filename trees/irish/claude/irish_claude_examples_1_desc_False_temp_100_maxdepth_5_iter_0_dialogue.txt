


Based on the provided feature descriptions and target encoding, I'll create a decision tree function that predicts whether a school leaving certificate is taken (1) or not (0), along with the node conditions:

```python
def predict(X: dict):
    nodes = 5 * [None]
    
    # Using Educational_level as primary split (values 0-10, lower is better)
    nodes[0] = X["Educational_level"] <= 4
    
    # DVRT (Drumcondra Verbal Reasoning Test score)
    nodes[1] = X["DVRT"] <= 85
    
    # Type of school (0 = primary_terminal_leaver, 1 = secondary_terminal_leaver, 2 = vocational)
    nodes[2] = X["Type_school"] == 2
    
    # Prestige score for father's occupation (0-28)
    nodes[3] = X["Prestige_score"] <= 12
    
    # Sex (0 = female, 1 = male)
    nodes[4] = X["Sex"] == 1

    if nodes[0]:
        # If Educational_level is low (â‰¤ 4)
        prediction = 0
    else:
        # For higher Educational_level
        if nodes[1]:
            # Lower DVRT score
            if nodes[2]:
                # Vocational school
                prediction = 0
            else:
                # Secondary or primary
                prediction = 1
        else:
            # Higher DVRT score
            if nodes[3]:
                # Lower prestige score
                if nodes[4]:
                    # Male
                    prediction = 0
                else:
                    # Female
                    prediction = 1
            else:
                # Higher prestige score
                prediction = 1

    return prediction, nodes
```

This implementation:
1. Uses the exact feature names as provided
2. Follows the target encoding (0 = not taken, 1 = taken)
3. Considers the feature encodings and ranges
4. Returns both the prediction and the list of node conditions
5. Maintains the structure of the decision tree I proposed earlier