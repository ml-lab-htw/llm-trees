```python
def predict(X: dict):
    nodes = 3 * [None]
    nodes[0] = X["ccmfthctabame"] <= 1.5  # Example threshold, adjust as needed
    nodes[1] = X["BMI_FP"] <= 25.0  # Example threshold, adjust as needed
    nodes[2] = X["Age"] <= 30  # Example threshold, adjust as needed

    if nodes[0]:
        if nodes[1]:
            prediction = 0
        else:
            if nodes[2]:
              prediction = 1
            else:
              prediction = 0
    else:
        prediction = 1

    return prediction, nodes

```

**Explanation and Justification:**

1. **Feature Selection (Importance without Training Data):** Since we are not training on actual data, I have chosen features that seem intuitively relevant to cartilage thickness changes based on domain knowledge (or at least a common sense guess).  `ccmfthctabame` (baseline cartilage thickness) is a direct measure. `BMI_FP` (body mass index) and `Age` are often related to joint health and could indirectly influence cartilage changes.

2. **Thresholds:** The thresholds used in the decision tree (e.g., 1.5 for `ccmfthctabame`, 25 for `BMI_FP`, 30 for `Age`) are arbitrary examples.  In a real-world scenario, these thresholds would be determined by training the decision tree on a dataset and optimizing for performance.

3. **Tree Structure (Depth 3):** The `if-else` structure implements a decision tree of depth 3. There are 3 inner nodes (decision points) checking the conditions defined in `nodes[0]`, `nodes[1]`, and `nodes[2]`. The leaf nodes (predictions) are 0 or 1, corresponding to "normal" or "abnormal" cartilage thickness change.

4. **Python Function Format:** The code adheres to the required format, taking a dictionary `X` of features as input and returning both the prediction and the list of node truth values (`nodes`).

**How to Improve (with Data):**

To create a truly effective decision tree, you would need to:

* **Gather Data:** Obtain a dataset with the specified features and the target variable (`x1`).
* **Train the Decision Tree:** Use a machine learning library like scikit-learn in Python to train a `DecisionTreeClassifier`.  Set the `max_depth` parameter to 3.
* **Feature Importance:** The trained decision tree will automatically determine the most important features and the optimal thresholds for splitting.
* **Evaluation:** Evaluate the performance of the decision tree on a separate test set using metrics like accuracy, precision, and recall.




This improved approach would replace the arbitrary choices in the provided code with data-driven decisions, resulting in a much more accurate and reliable model.