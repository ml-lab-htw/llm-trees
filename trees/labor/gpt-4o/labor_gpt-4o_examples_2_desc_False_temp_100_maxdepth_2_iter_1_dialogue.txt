


Certainly! Below is a Python function that implements the decision tree with a maximum depth of 2 based on the given specifications. 

```python
def predict(X: dict):
    nodes = [None, None]

    # First condition
    nodes[0] = X["wage increase first year"] > 4.0

    if nodes[0]:
        # Second condition when wage increase in first year > 4.0
        nodes[1] = X["pension"] != "none"

        if nodes[1]:
            prediction = 1  # good
        else:
            prediction = 0  # bad
    else:
        prediction = 0  # bad

    return prediction, nodes

# Example usage:
# X = {
#     'duration': 3,
#     'wage increase first year': 5.0,
#     'wage increase second year': 3.2,
#     'wage increase third year': 3.1,
#     'cost of living adjustment': 'none',
#     'working hours': 37,
#     'pension': 'empl_contr',
#     'standby pay': 10,
#     'shift differential': 15,
#     'education allowance': True,
#     'statutory holidays': 12,
#     'vacation': 'avg',
#     'longterm disability assistance': True,
#     'contribution to dental plan': 'full',
#     'bereavement assistance': True,
#     'contribution to health plan': 'half'
# }
# prediction, nodes = predict(X)
# print(f"Prediction: {prediction}, Nodes: {nodes}")
```

Explanation:
- **First Decision Node (`nodes[0]`)**: Checks if the "wage increase in first year" is greater than 4.0%.
- **Second Decision Node (`nodes[1]`)**: If the first condition is satisfied (i.e., wage increase in first year > 4.0), it checks if the "pension" is not "none".

Outcome:
- The function returns the prediction (1 for good, 0 for bad) and a list of the truth values (nodes) for each decision.

The `predict` function can be extended to include more conditions by adding more nodes and conditions within the if-else structure.