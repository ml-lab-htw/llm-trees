


Based on the decision tree we created earlier and using the provided feature keys and target variable encoding, here's the Python function that predicts the outcome of labor negotiations (`0 = bad`, `1 = good`) and returns a list of truth values for the inner nodes:

```python
def predict(X: dict):
    """
    Predict the outcome of labor negotiations based on input features.

    Parameters:
    X (dict): A dictionary containing feature values. Keys must match the feature names exactly.

    Returns:
    tuple: A tuple containing:
        - prediction (int): 0 for "bad" and 1 for "good".
        - nodes (list): A list of truth values (1 for True, 0 for False) for the inner nodes.
    """
    nodes = 2 * [None]
    
    # Node 0: Wage increase in the first year of the contract
    nodes[0] = X["wage increase first year"] <= 4.5
    
    # Node 1: Number of paid vacation days
    if nodes[0]:  # Wage increase in first year <= 4.5
        nodes[1] = X["contribution to health plan"] == 0
    else:  # Wage increase in first year > 4.5
        nodes[1] = X["vacation"] == 1  # "ba" = below average
    
    # Decision logic based on the nodes
    if nodes[0]:  # Wage increase in first year <= 4.5
        if nodes[1]:  # Contribution to health plan is "none"
            prediction = 0  # bad
        else:  # Contribution to health plan is not "none"
            prediction = 1  # good
    else:  # Wage increase in first year > 4.5
        if nodes[1]:  # Vacation is "below average"
            prediction = 0  # bad
        else:  # Vacation is not "below average"
            prediction = 1  # good

    # Convert boolean values in nodes to integers (1 for True, 0 for False)
    nodes = [int(node) for node in nodes]
    
    return prediction, nodes
```

### Explanation:
1. **Nodes in the Decision Tree**:
   - `nodes[0]`: Checks if the wage increase in the first year of the contract is less than or equal to 4.5%.
   - `nodes[1]`: If `nodes[0]` is `True`, it checks if the contribution to the health plan is `"none"`. Otherwise, it checks if the vacation is `"ba"` (below average).

2. **Prediction Logic**:
   - If the wage increase in the first year is small (≤ 4.5%) and the contribution to the health plan is `"none"`, the outcome is classified as `bad` (0).
   - If the wage increase in the first year is small (≤ 4.5%) and the contribution to the health plan is not `"none"`, the outcome is `good` (1).
   - If the wage increase in the first year is large (> 4.5%) and the vacation is `"below average"`, the outcome is `bad` (0).
   - If the wage increase in the first year is large (> 4.5%) and the vacation is not `"below average"`, the outcome is `good` (1).

3. **Return Values**:
   - `prediction`: The predicted class (`0 = bad`, `1 = good`).
   - `nodes`: A list of truth values (`1` for `True`, `0` for `False`) representing whether the conditions of the inner nodes were satisfied.

---

### Example Usage:
```python
# Example input features
features = {
    "duration": 3,
    "wage increase first year": 4.0,
    "wage increase second year": 3.5,
    "wage increase third year": 3.0,
    "cost of living adjustment": "none",
    "working hours": 37,
    "pension": "ret_allw",
    "standby pay": 10,
    "shift differential": 5,
    "education allowance": True,
    "statutory holidays": 12,
    "vacation": "avg",
    "longterm disability assistance": True,
    "contribution to dental plan": "half",
    "bereavement assistance": True,
    "contribution to health plan": "none"
}

# Make a prediction
prediction, nodes = predict(features)

print("Prediction:", "good" if prediction == 1 else "bad")
print("Nodes:", nodes)
```

### Example Output:
```
Prediction: bad
Nodes: [1, 1]
```

This output means that the first condition (`wage increase first year <= 4.5`) was satisfied (`1`), and the second condition (`contribution to health plan == 0`) was also satisfied (`1`), leading to a prediction of `bad`.
