Based on the Features and target variable, here's a decision tree classifier with a maximum depth of 2 (using the most relevant features, WC/TA and EBIT/TA):

```python
def predict(X: dict):
    nodes = 2 * [None]
    nodes[0] = X["WC/TA"] <= 0.1
    nodes[1] = X["EBIT/TA"] <= 0.05
    
    if nodes[0]:
        if nodes[1]:
            prediction = 1  # Likely to go bankrupt
        else:
            prediction = 0  # Not likely to go bankrupt
    else:
        prediction = 0  # Not likely to go bankrupt

    return prediction, nodes
```

### Explanation:
- **Node 0**: If the company's Working Capital/Total Assets (WC/TA) is less than or equal to 0.1, it indicates potential liquidity issues, which could lead to bankruptcy.
- **Node 1**: If, in addition to low WC/TA, the company's Earnings Before Interest and Tax/Total Assets (EBIT/TA) is less than or equal to 0.05, this indicates poor profitability. Thus, the company is more likely to go bankrupt.
- If both conditions are satisfied, the model predicts bankruptcy (`1`), while if the conditions are not satisfied, it predicts the company will not go bankrupt (`0`).

### Usage:
You can input a dictionary representing a company's metrics, and the function will return:
1. The bankruptcy prediction (`0` = not bankrupt, `1` = bankrupt).
2. A list of boolean values showing whether each condition (inner node) was satisfied (`1` for true, `0` for false).

Example usage:
```python
X = {
    "WC/TA": 0.08,
    "RE/TA": 0.15,
    "EBIT/TA": 0.03,
    "S/TA": 0.5,
    "BVE/BVL": 1.2
}

prediction, node_conditions = predict(X)
print("Prediction:", prediction)
print("Node conditions:", node_conditions)
```
